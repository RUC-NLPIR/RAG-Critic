# ----Global Paths----
# Paths to retrieval models
model2path:
  e5: intfloat/e5-base-v2
  qwen2.5-72B-instruct: Qwen/Qwen2.5-72B-Instruct

# Pooling methods for each embedding model
model2pooling:
  e5: "mean"

# Indexes path for retrieval models
method2index:
  e5: wiki_dpr_100w/e5_flat_inner.index

# ----Environment Settings----
gpu_id: "0,1,2,3,4,5,6,7"
dataset_name: "nq"
split: ["dev",'test']

# Sampling configurations for testing
test_sample_num: 1000
random_sample: False
save_intermediate_data: True
# Seed for reproducibility
seed: 2024

# Directory paths for data and outputs
data_dir: "datasets/"
save_dir: "result/"

# ----Retrieval Settings----
retrieval_method: "e5" # name or path of the retrieval model
index_path: ~ # Set automatically if not provided
corpus_path: "wiki_dpr_100w/wiki_dump.jsonl"
retrieval_pooling_method: ~

retrieval_topk: 5
retrieval_batch_size: 256
retrieval_use_fp16: True
retrieval_query_max_length: 128
save_retrieval_cache: False
use_retrieval_cache: False
faiss_gpu: False
retrieval_cache_path: ~

use_reranker: False
rerank_model_name: e5
rerank_model_path: ~
rerank_pooling_method: ~
rerank_use_fp16: True
rerank_topk: 5
rerank_max_length: 512
rerank_batch_size: 256

# ----Generator Settings----
use_vllm: True
generator_model: "llama3.1-8B-instruct"  # name or path of the generator
generator_max_input_len: 8192
generator_batch_size: 4
generation_params:
  do_sample: False
  max_tokens: 32
  temperature: 0.1
  top_p: 1.0
gpu_memory_utilization: 0.8

# ----Evaluation Settings----
metrics: ['em','f1','acc','precision','recall','input_tokens']
save_metric_score: True

